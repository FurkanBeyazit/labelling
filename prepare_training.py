"""
Prepare YOLO training dataset from labeled frames.
Collects all approved frames and creates train/val split.
"""
import os
import sys
import shutil
import random
import argparse
from pathlib import Path

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from backend.config import FRAMES_DIR, LABELS_DIR, CLASS_NAMES


def collect_approved_samples(frames_dir: Path, labels_dir: Path):
    """
    Collect all approved samples (frames with corresponding label files).
    Returns list of (image_path, label_path) tuples.
    """
    samples = []

    # Iterate through all video folders in frames directory
    if not frames_dir.exists():
        print(f"Frames directory not found: {frames_dir}")
        return samples

    for video_dir in frames_dir.iterdir():
        if not video_dir.is_dir():
            continue

        video_id = video_dir.name
        video_labels_dir = labels_dir / video_id

        # Find all frame images
        for img_path in video_dir.glob("*.jpg"):
            frame_name = img_path.stem
            label_path = video_labels_dir / f"{frame_name}.txt"

            # Only include if label exists (approved)
            if label_path.exists():
                samples.append((img_path, label_path))

    return samples


def convert_label_to_class_id(label_path: Path, output_path: Path):
    """
    Convert label file from class_name format to class_id format.
    Input:  class_name x_center y_center width height [confidence]
    Output: class_id x_center y_center width height
    """
    lines = []

    with open(label_path, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 5:
                class_name = parts[0]
                coords = parts[1:5]  # x_center, y_center, width, height

                # Get class ID
                try:
                    class_id = CLASS_NAMES.index(class_name)
                except ValueError:
                    print(f"  Warning: Unknown class '{class_name}' in {label_path}")
                    continue

                # Write as: class_id x y w h
                lines.append(f"{class_id} {' '.join(coords)}")

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))


def create_data_yaml(output_dir: Path, class_names: list):
    """Create data.yaml for YOLO training."""
    yaml_content = f"""# YOLO Training Dataset
# Generated by prepare_training.py

path: {output_dir.absolute()}
train: images/train
val: images/val

# Classes
names:
"""
    for i, name in enumerate(class_names):
        yaml_content += f"  {i}: {name}\n"

    yaml_path = output_dir / "data.yaml"
    with open(yaml_path, 'w', encoding='utf-8') as f:
        f.write(yaml_content)

    return yaml_path


def prepare_dataset(
    output_dir: str = "dataset",
    split_ratio: float = 0.8,
    shuffle: bool = True
):
    """
    Prepare YOLO training dataset.

    Args:
        output_dir: Output directory name
        split_ratio: Train/val split ratio (0.8 = 80% train, 20% val)
        shuffle: Whether to shuffle samples before splitting
    """
    output_path = Path(output_dir)

    print("=" * 50)
    print("YOLO Training Dataset Preparation")
    print("=" * 50)
    print()

    # Collect samples
    print("Collecting approved samples...")
    samples = collect_approved_samples(FRAMES_DIR, LABELS_DIR)

    if not samples:
        print("No approved samples found!")
        print("Make sure you have labeled and approved some frames first.")
        return

    print(f"Found {len(samples)} approved samples")
    print()

    # Shuffle if requested
    if shuffle:
        random.shuffle(samples)
        print("Samples shuffled")

    # Split into train/val
    split_idx = int(len(samples) * split_ratio)
    train_samples = samples[:split_idx]
    val_samples = samples[split_idx:]

    print(f"Train samples: {len(train_samples)}")
    print(f"Val samples: {len(val_samples)}")
    print()

    # Create directory structure
    print(f"Creating output directory: {output_path.absolute()}")

    dirs = [
        output_path / "images" / "train",
        output_path / "images" / "val",
        output_path / "labels" / "train",
        output_path / "labels" / "val",
    ]

    for d in dirs:
        d.mkdir(parents=True, exist_ok=True)

    # Copy files
    print()
    print("Copying train files...")
    for img_path, label_path in train_samples:
        # Copy image
        dst_img = output_path / "images" / "train" / img_path.name
        shutil.copy2(img_path, dst_img)

        # Convert and copy label
        dst_label = output_path / "labels" / "train" / f"{img_path.stem}.txt"
        convert_label_to_class_id(label_path, dst_label)

    print("Copying val files...")
    for img_path, label_path in val_samples:
        # Copy image
        dst_img = output_path / "images" / "val" / img_path.name
        shutil.copy2(img_path, dst_img)

        # Convert and copy label
        dst_label = output_path / "labels" / "val" / f"{img_path.stem}.txt"
        convert_label_to_class_id(label_path, dst_label)

    # Create train.txt and val.txt (image paths)
    print("Creating train.txt and val.txt...")

    train_txt_path = output_path / "train.txt"
    with open(train_txt_path, 'w', encoding='utf-8') as f:
        for img_path, _ in train_samples:
            abs_path = (output_path / "images" / "train" / img_path.name).absolute()
            f.write(f"{abs_path}\n")

    val_txt_path = output_path / "val.txt"
    with open(val_txt_path, 'w', encoding='utf-8') as f:
        for img_path, _ in val_samples:
            abs_path = (output_path / "images" / "val" / img_path.name).absolute()
            f.write(f"{abs_path}\n")

    # Create data.yaml
    print("Creating data.yaml...")
    yaml_path = create_data_yaml(output_path, CLASS_NAMES)

    # Create classes.txt
    classes_path = output_path / "classes.txt"
    with open(classes_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(CLASS_NAMES))

    # Summary
    print()
    print("=" * 50)
    print("Dataset preparation complete!")
    print("=" * 50)
    print()
    print(f"Output directory: {output_path.absolute()}")
    print()
    print("Structure:")
    print(f"  {output_path}/")
    print(f"  ├── images/")
    print(f"  │   ├── train/  ({len(train_samples)} images)")
    print(f"  │   └── val/    ({len(val_samples)} images)")
    print(f"  ├── labels/")
    print(f"  │   ├── train/  ({len(train_samples)} labels)")
    print(f"  │   └── val/    ({len(val_samples)} labels)")
    print(f"  ├── train.txt   (image paths for training)")
    print(f"  ├── val.txt     (image paths for validation)")
    print(f"  ├── data.yaml   (YOLO config)")
    print(f"  └── classes.txt")
    print()
    print("To train YOLO:")
    print(f"  yolo detect train data={yaml_path.absolute()} model=yolo11n.pt epochs=100")
    print()

    # Class distribution
    print("Class distribution:")
    class_counts = {}
    for _, label_path in samples:
        with open(label_path, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split()
                if parts:
                    class_name = parts[0]
                    class_counts[class_name] = class_counts.get(class_name, 0) + 1

    for name in CLASS_NAMES:
        count = class_counts.get(name, 0)
        if count > 0:
            print(f"  {name}: {count}")


def main():
    parser = argparse.ArgumentParser(
        description="Prepare YOLO training dataset from labeled frames"
    )
    parser.add_argument(
        "--output", "-o",
        default="dataset",
        help="Output directory (default: dataset)"
    )
    parser.add_argument(
        "--split", "-s",
        type=float,
        default=0.8,
        help="Train/val split ratio (default: 0.8)"
    )
    parser.add_argument(
        "--shuffle",
        action="store_true",
        help="Shuffle samples before splitting"
    )
    parser.add_argument(
        "--no-shuffle",
        action="store_true",
        help="Do not shuffle samples (keep video order)"
    )

    args = parser.parse_args()

    # Default is shuffle, unless --no-shuffle specified
    shuffle = not args.no_shuffle

    prepare_dataset(
        output_dir=args.output,
        split_ratio=args.split,
        shuffle=shuffle
    )


if __name__ == "__main__":
    main()
